{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "import sort_RAFT_table as sRt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import re\n",
    "from scipy.optimize import curve_fit\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t0h-conversion', 't1h-conversion', 't2h-conversion', 't4h-conversion', 't6h-conversion', 't8h-conversion', 't10h-conversion', 't15h-conversion']\n",
      "['t0h-Mn', 't1h-Mn', 't2h-Mn', 't4h-Mn', 't6h-Mn', 't8h-Mn', 't10h-Mn', 't15h-Mn']\n",
      "['t0h-Mw', 't1h-Mw', 't2h-Mw', 't4h-Mw', 't6h-Mw', 't8h-Mw', 't10h-Mw', 't15h-Mw']\n"
     ]
    }
   ],
   "source": [
    "# ToDo:\n",
    "#  in ist Monomer und Mn dann\n",
    "#       sortieren nach Umsatz dahingehend dann nach k√ºrzester Zeit\n",
    "#       Tabellenausgabe dazu Kinetik Kurve, Reaktionsbedingungen (LM, Raft agent, Zeit...)\n",
    "#  am besten als interaktive website Tabelle.\n",
    "\n",
    "# rectify/balance the table\n",
    "sRt.df[\"t6h-conversion\"] = np.nan\n",
    "sRt.df[\"t10h-conversion\"] = np.nan\n",
    "\n",
    "# get all conversion headers, sort them by the hours\n",
    "conversion_list = []\n",
    "for column in sRt.df.columns:\n",
    "    if \"conversion\" in column:\n",
    "        conversion_list.append(column)\n",
    "\n",
    "conversion_list.sort(key=lambda x: int(re.findall(r\"\\d+\", x)[0]))\n",
    "\n",
    "# get all the Mn and Mw headers\n",
    "Mn_list = []\n",
    "Mw_list = []\n",
    "for column in sRt.df.columns:\n",
    "    if \"Mn\" in column:\n",
    "        Mn_list.append(column)\n",
    "    if \"Mw\" in column:\n",
    "        Mw_list.append(column)\n",
    "\n",
    "print(conversion_list, Mn_list, Mw_list, sep=\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The timer was reset to 0 after the first closing of reactors in the \"t = 0\"-sampling-step\n"
     ]
    },
    {
     "data": {
      "text/plain": "                     0         1         2         4         6         8  \\\nReactor                                                                    \n1                    0  1.005556  2.011111  4.018056  6.008333  8.016667   \n2                    0  1.005556  2.011111  4.018056  6.008333  8.016667   \n3                    0  1.073611  2.068056  4.077778  6.063889  8.090278   \n4                    0  1.073611  2.068056  4.077778  6.063889  8.090278   \n5                    0  1.131944  2.125000  4.143056  6.120833  8.180556   \n6                    0  1.131944  2.125000  4.143056  6.120833  8.180556   \n7                    0  1.191667  2.184722  4.205556  6.180556  8.256944   \n8                    0  1.191667  2.184722  4.205556  6.180556  8.256944   \n9                    0  1.251389  2.241667  4.273611  6.237500  8.338889   \n10                   0  1.251389  2.241667  4.273611  6.237500  8.338889   \n11                   0  1.312500  2.301389  4.336111  6.295833  8.415278   \n12                   0  1.312500  2.301389  4.336111  6.295833  8.415278   \n13                   0  1.373611  2.369444  4.409722  6.358333  8.501389   \n14                   0  1.373611  2.369444  4.409722  6.358333  8.501389   \n15                   0  1.437500  2.430556  4.475000  6.416667  8.581944   \nclosing of reactors  0  1.481944  2.476389  4.526389  6.461111  8.643056   \n\n                            10         15  \nReactor                                    \n1                    10.011111  15.016667  \n2                    10.011111  15.016667  \n3                    10.084722  15.098611  \n4                    10.084722  15.098611  \n5                    10.158333  15.200000  \n6                    10.158333  15.200000  \n7                    10.233333  15.291667  \n8                    10.233333  15.291667  \n9                    10.306944  15.381944  \n10                   10.306944  15.381944  \n11                   10.383333  15.472222  \n12                   10.383333  15.472222  \n13                   10.466667  15.568056  \n14                   10.466667  15.568056  \n15                   10.541667  15.658333  \nclosing of reactors  10.604167  15.730556  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>4</th>\n      <th>6</th>\n      <th>8</th>\n      <th>10</th>\n      <th>15</th>\n    </tr>\n    <tr>\n      <th>Reactor</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1.005556</td>\n      <td>2.011111</td>\n      <td>4.018056</td>\n      <td>6.008333</td>\n      <td>8.016667</td>\n      <td>10.011111</td>\n      <td>15.016667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1.005556</td>\n      <td>2.011111</td>\n      <td>4.018056</td>\n      <td>6.008333</td>\n      <td>8.016667</td>\n      <td>10.011111</td>\n      <td>15.016667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1.073611</td>\n      <td>2.068056</td>\n      <td>4.077778</td>\n      <td>6.063889</td>\n      <td>8.090278</td>\n      <td>10.084722</td>\n      <td>15.098611</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1.073611</td>\n      <td>2.068056</td>\n      <td>4.077778</td>\n      <td>6.063889</td>\n      <td>8.090278</td>\n      <td>10.084722</td>\n      <td>15.098611</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1.131944</td>\n      <td>2.125000</td>\n      <td>4.143056</td>\n      <td>6.120833</td>\n      <td>8.180556</td>\n      <td>10.158333</td>\n      <td>15.200000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>1.131944</td>\n      <td>2.125000</td>\n      <td>4.143056</td>\n      <td>6.120833</td>\n      <td>8.180556</td>\n      <td>10.158333</td>\n      <td>15.200000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>1.191667</td>\n      <td>2.184722</td>\n      <td>4.205556</td>\n      <td>6.180556</td>\n      <td>8.256944</td>\n      <td>10.233333</td>\n      <td>15.291667</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>1.191667</td>\n      <td>2.184722</td>\n      <td>4.205556</td>\n      <td>6.180556</td>\n      <td>8.256944</td>\n      <td>10.233333</td>\n      <td>15.291667</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>1.251389</td>\n      <td>2.241667</td>\n      <td>4.273611</td>\n      <td>6.237500</td>\n      <td>8.338889</td>\n      <td>10.306944</td>\n      <td>15.381944</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>1.251389</td>\n      <td>2.241667</td>\n      <td>4.273611</td>\n      <td>6.237500</td>\n      <td>8.338889</td>\n      <td>10.306944</td>\n      <td>15.381944</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>1.312500</td>\n      <td>2.301389</td>\n      <td>4.336111</td>\n      <td>6.295833</td>\n      <td>8.415278</td>\n      <td>10.383333</td>\n      <td>15.472222</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>1.312500</td>\n      <td>2.301389</td>\n      <td>4.336111</td>\n      <td>6.295833</td>\n      <td>8.415278</td>\n      <td>10.383333</td>\n      <td>15.472222</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>1.373611</td>\n      <td>2.369444</td>\n      <td>4.409722</td>\n      <td>6.358333</td>\n      <td>8.501389</td>\n      <td>10.466667</td>\n      <td>15.568056</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>1.373611</td>\n      <td>2.369444</td>\n      <td>4.409722</td>\n      <td>6.358333</td>\n      <td>8.501389</td>\n      <td>10.466667</td>\n      <td>15.568056</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>1.437500</td>\n      <td>2.430556</td>\n      <td>4.475000</td>\n      <td>6.416667</td>\n      <td>8.581944</td>\n      <td>10.541667</td>\n      <td>15.658333</td>\n    </tr>\n    <tr>\n      <th>closing of reactors</th>\n      <td>0</td>\n      <td>1.481944</td>\n      <td>2.476389</td>\n      <td>4.526389</td>\n      <td>6.461111</td>\n      <td>8.643056</td>\n      <td>10.604167</td>\n      <td>15.730556</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def change_timeformat(time_format):\n",
    "    h_m_s = str(time_format).split(\":\")\n",
    "    m_format = int(h_m_s[0]) * 60 + int(h_m_s[1]) + int(h_m_s[2]) / 60\n",
    "    return m_format\n",
    "\n",
    "def change_timeformat_h(time_format):\n",
    "    h_m_s = str(time_format).split(\":\")\n",
    "    h_format = int(h_m_s[0]) + (int(h_m_s[1]) + int(h_m_s[2]) / 60) /60\n",
    "    return h_format\n",
    "\n",
    "# creating a table as a lookup to correct all sample measurement times\n",
    "\n",
    "# get the hours from the headers with regex\n",
    "hours_list = []\n",
    "two_digit_regex = r\"\\d+\"\n",
    "for column in conversion_list:\n",
    "    hours_list.append(int(re.findall(two_digit_regex, column)[0]))\n",
    "hours_list.sort()\n",
    "\n",
    "exact_times = pd.read_excel(sRt.INPUT_FILE_PATH, sheet_name=\"exact sampling times\")\n",
    "\n",
    "time_correction_df = pd.DataFrame(data=exact_times.iloc[3:12, 3:])\n",
    "time_correction_df.columns = exact_times.loc[2][3:]\n",
    "\n",
    "time_correction_df.reset_index(inplace=True, drop=True)\n",
    "ext_time_corr_df_data =[]\n",
    "for row in time_correction_df.iterrows():\n",
    "    reactor_nr = row[1][\"Reactor\"]\n",
    "    if type(reactor_nr) == int or reactor_nr == \"closing of reactors\": # that applies to reactor 15 and the closing of reactors\n",
    "        row[1][\"Reactor\"] = str(reactor_nr)\n",
    "        ext_time_corr_df_data.append(row[1])\n",
    "    else: # that applies to all reactors which are described per row in pairs like \"3+4\"\n",
    "        reactor_nr_s = (row[1][\"Reactor\"]).split(\"+\")\n",
    "        for reactor_nr in reactor_nr_s:\n",
    "            row[1][\"Reactor\"] = reactor_nr\n",
    "            ext_time_corr_df_data.append(row[1].copy())\n",
    "ext_time_corr_df = pd.DataFrame(data=ext_time_corr_df_data, columns=exact_times.loc[2][3:])\n",
    "ext_time_corr_df.reset_index(drop=True, inplace=True)\n",
    "print(\"The timer was reset to 0 after the first closing of reactors in the \\\"t = 0\\\"-sampling-step\")\n",
    "ext_time_corr_df.columns = [\"Reactor\", 0, 1, 2, 4, 6, 8, 10, 15]\n",
    "\n",
    "# change time format to minutes and set\n",
    "time_cols = ext_time_corr_df.columns.difference([\"Reactor\"])\n",
    "ext_time_corr_df[time_cols] = ext_time_corr_df[time_cols].apply(lambda x: [change_timeformat_h(d) for d in x])\n",
    "ext_time_corr_df[0] = ext_time_corr_df[0].apply(lambda x: 0 )\n",
    "\n",
    "# set index to reactor\n",
    "ext_time_corr_df.set_index(\"Reactor\", inplace=True)\n",
    "\n",
    "ext_time_corr_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "outputs": [
    {
     "data": {
      "text/plain": "{'1': 'Styrene',\n '2': '4-Chlorostyrene',\n '3': '4-Bromostyrene',\n '4': '4-Methylstyrene',\n '5': '4-Methoxystyrene',\n '16': '4-tert-Butylstyrene',\n '6': 'Methyl methacrylate',\n '7': 'Butyl methacrylate',\n '8': 'Lauryl methacrylate',\n '9': '(2-Dimethylaminoethyl)methacrylate',\n '10': 'Benzyl methacrylate',\n '11': 'Methyl acrylate ',\n '12': 'Butyl acrylate',\n '13': 'Lauryl acrylate',\n '14': 'Dimethylaminoethylacrylate',\n '15': 'Benzyl acrylate',\n 'A': '2-Cyan-2-propylbenzodithioat',\n 'B': '4-Cyano-4-(phenylcarbonothioylthio)pentanoic acid',\n 'C': '2-Phenyl-2-propyl benzodithioate',\n 'D': '2-Cyano-2-propyl dodecyl trithiocarbonate',\n 'E': '2-(Dodecylthiocarbonothioylthio)-2-methylpropionic acid',\n 'F': 'Cyanomethyl dodecyl trithiocarbonate',\n 'G': 'Benzyl 1H-pyrrole-1-carbodithioate',\n 'H': '2-Cyanopropan-2-yl N-methyl-N-(pyridin-4-yl)carbamodithioate',\n 'I': 'S,S-Dibenzyl trithiocarbonate',\n 'J': 'Cyanomethyl methyl(phenyl)carbamodithioate',\n 'DMF': 'Dimethylformamide',\n 'Tol': 'Toluene',\n 'DMSO': 'Dimethylsulfoxide'}"
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace the \"sample determiner\" with columns describing for the experiment number (next cell) and the actual reagents that made out the \"determiner\"\n",
    "reaction_descriptors_dict = {}\n",
    "abbreviation_keys = pd.read_excel(sRt.INPUT_FILE_PATH, sheet_name=\"Legend for Abbreviations\")\n",
    "abbreviation_keys.dropna(inplace=True)\n",
    "for row in abbreviation_keys.itertuples():\n",
    "    reaction_descriptors_dict[str(row.Symbol)] = row.Name\n",
    "\n",
    "reaction_descriptors_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "# plotting the kinetic curves of the RAFT polymerization\n",
    "# generate a reformatted table with all entries attributing to a sample analysis taken, described with a column of the right time\n",
    "\n",
    "# ToDo: implement Mn too, and the different columns for the reaction substances: Monomer, Raft-Agent, Solvent\n",
    "#    maybe also just do that later in the kinetic_curves_df\n",
    "\n",
    "# create a dataframe with just the information needed to append to\n",
    "kinetic_curves = []\n",
    "for index, polymerisation_kinetic in sRt.df.iterrows():\n",
    "\n",
    "    kinetic_curve_entries = pd.DataFrame(index=range(len(polymerisation_kinetic[conversion_list])),\n",
    "        data={\"time\" : hours_list, \"conversion\" : polymerisation_kinetic[conversion_list].values,\n",
    "         \"Mn\" : polymerisation_kinetic[Mn_list].values, \"Mw\" : polymerisation_kinetic[Mw_list].values,\n",
    "         # , \"reactor\" : polymerisation_kinetic[\"reactor\"] reactor is not needed since the time is corrected\n",
    "         })\n",
    "\n",
    "    kinetic_curve_entries[\"exp_nr\"] = str(index)\n",
    "    kinetic_curve_entries[\"monomer\"] = reaction_descriptors_dict[polymerisation_kinetic[\"monomer\"]]\n",
    "    kinetic_curve_entries[\"RAFT-Agent\"] = reaction_descriptors_dict[polymerisation_kinetic[\"RAFT-Agent\"]]\n",
    "    kinetic_curve_entries[\"solvent\"] = reaction_descriptors_dict[polymerisation_kinetic[\"solvent\"]]\n",
    "\n",
    "    # the times are dependent on the current reactor, get current\n",
    "    current_reactor_nr = str(polymerisation_kinetic[\"reactor\"])\n",
    "    current_time_list = ext_time_corr_df.loc[current_reactor_nr]\n",
    "    kinetic_curve_entries[\"time\"] = list(current_time_list)\n",
    "\n",
    "    kinetic_curves.append(kinetic_curve_entries)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [],
   "source": [
    "# reset Nans of Mn_t0 and Mw_t0 to 0 where the values are NaN\n",
    "for kinetic_curve in kinetic_curves:\n",
    "    kinetic_curve[\"Mn\"].fillna(0, inplace=True)\n",
    "    kinetic_curve[\"Mw\"].fillna(0, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "deprecated: more theoretical accurate version but practically worse applicable\n",
    "    # L is responsible for scaling the output range from [0,1] to [0,L]\n",
    "    # b\n",
    "    # k is responsible for scaling the input, which remains in (-inf,inf)\n",
    "    # x0\n",
    "def sigmoid (x, L ,x0, k, b):\n",
    "    y = L / (1 + np.exp(-k*(x-x0)))+b\n",
    "    return (y)\n",
    "\n",
    "def sigmoid_derivative(x, L ,x0, k, b): # ToDo: check if this is the correct derivative\n",
    "    y = (L*k*np.exp(-k*(x-x0)))/((np.exp(-k*(x-x0))+1)**2)\n",
    "    return (y)\n",
    "\n",
    "\n",
    "'''\n",
    "def neg_growth(x, l, k):\n",
    "    y = l * (1 - np.exp(k * (-x)))\n",
    "    return y\n",
    "\n",
    "def neg_growth_derivative(x, l, k):\n",
    "    y = l * k * np.exp(k*(-x))\n",
    "    return y\n",
    "\n",
    "def linear_growth(x, m):\n",
    "    y = m * x\n",
    "    return y\n",
    "\n",
    "def linear_growth_derivative(m):\n",
    "    return m\n",
    "\n",
    "'''\n",
    "xrange = np.arange(-0.2, 5, 0.1)\n",
    "example_fig = px.line()\n",
    "for testparams in ([1,1], [2,1], [1,2]):\n",
    "    example_fig.add_scatter(x=xrange, y=neg_growth(xrange, *testparams))\n",
    "    example_fig.add_scatter(x=xrange, y=neg_growth_derivative(xrange, *testparams), opacity=0.5, line=dict(dash=\"dot\"))\n",
    "\n",
    "print(\"visualisation of the functions\")\n",
    "example_fig.show()\n",
    "# '''\n",
    "print(\"functions loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # manually exclude experiment 301 as it disturbs the covariance plotting and has an unreasonable conversion value course.\n",
    "if kinetic_curves[301][\"exp_nr\"].iloc[1] == \"301\":\n",
    "    print(kinetic_curves[301])\n",
    "    fig = px.line(kinetic_curves[301], x=\"time\", y=\"conversion\", title=f\"kinetic 301 \", labels={\"x\":\"time\", \"y\":\"conversion\"})\n",
    "    fig.show()\n",
    "    kinetic_curves.pop(301)\n",
    "else:\n",
    "    print(\"Cell was already run. Experiment is deleted.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.line(title=\"Kinetic Curve Fit\", labels={\"x\":\"time\", \"y\":\"conversion\"})\n",
    "colors = px.colors.qualitative.Plotly # set up a simple color palette\n",
    "extended_xdata = np.linspace(-1, 16.5, 100) # x data array for plotting the fits\n",
    "\n",
    "kinetics_df = pd.DataFrame() # create new dataframe with kinetics per row\n",
    "\n",
    "def add_fits_to_plot(fit_func, fit_func_derivative, fit_func_params, marker_dic):\n",
    "    fig.add_scatter(\n",
    "        x=extended_xdata, y=fit_func(extended_xdata, *fit_func_params),\n",
    "        opacity=1, line=dict(dash=\"dot\"), name=f\"{fit_func.__name__} fit\", marker=marker_dic)\n",
    "    fig.add_scatter(\n",
    "        x=extended_xdata, y=fit_func_derivative(extended_xdata, *fit_func_params),\n",
    "        opacity=0.3, line=dict(dash=\"dash\"), name=f\"{fit_func_derivative.__name__}\", marker=marker_dic)\n",
    "\n",
    "def fit_and_exclude_outliers(x, y, fit_func, p0, bounds, nan_policy=\"omit\", iteration=1, outliers=None):\n",
    "    outliers = outliers if outliers is not None else []\n",
    "\n",
    "    cf_data = curve_fit(f=fit_func, xdata=x, ydata=y, p0=p0, nan_policy=nan_policy, maxfev=800 * 10, bounds=bounds)\n",
    "\n",
    "    # calculate the fit points\n",
    "    fit_points = np.array([fit_func(x, *cf_data[0]) for x in x])\n",
    "    # calculate the standard deviation of the residuals between the fit and the data points\n",
    "    sigma = np.std(fit_points - y)\n",
    "\n",
    "    # exclude the outliers\n",
    "    msk = ~(np.abs(fit_points - y) > 2 * sigma)\n",
    "    if not msk.all():\n",
    "        return fit_and_exclude_outliers(x=x[msk], y=y[msk], fit_func=fit_func, p0=cf_data[0], bounds=bounds, nan_policy=nan_policy, iteration=iteration+1, outliers=outliers + [x[~msk]])\n",
    "\n",
    "    result = {\"x\": x, \"y\": y, \"p_opt\" : cf_data[0], \"p_cov\" : cf_data[1], \"excluded_points\" : (x[~msk],y[~msk]), \"iteration\" : iteration, \"outliers\" : outliers}\n",
    "    return result\n",
    "\n",
    "for idx, kinetic_curve in enumerate(kinetic_curves):\n",
    "    # first make sure the datapoints are in the right format and not sometimes int sometimes float\n",
    "    ydata = np.array(kinetic_curve[\"conversion\"].values, dtype=float)\n",
    "    xdata = np.array(kinetic_curve[\"time\"].values, dtype=float)\n",
    "    # exclude the nan values from the data\n",
    "    mask = ~np.isnan(ydata)\n",
    "    xdata, ydata = xdata[mask], ydata[mask]\n",
    "\n",
    "    # fitting section\n",
    "    p_initial = [max(ydata), 0.1] # this is a mandatory initial guess\n",
    "    ng_fit = fit_and_exclude_outliers(x=xdata, y=ydata, fit_func=neg_growth, p0=p_initial, bounds=([0, -np.inf], [1, np.inf]))\n",
    "\n",
    "    popt, pcov = ng_fit[\"p_opt\"], ng_fit[\"p_cov\"]\n",
    "    ydata, xdata = ng_fit[\"y\"], ng_fit[\"x\"]\n",
    "\n",
    "    # fit with linear growth\n",
    "    # l_fit = fit_and_exclude_outliers(\n",
    "    #     x=xdata, y=ydata, fit_func=linear_growth, p0=[max(ydata)/7], bounds=([0], [np.inf]))\n",
    "\n",
    "    # calculate the squared error of fit and data points\n",
    "    y_st =[]\n",
    "    x_st = []\n",
    "    for y_val, x_val in zip(ydata, xdata):\n",
    "        if np.isnan(y_val) or np.isnan(x_val):\n",
    "            continue\n",
    "        y_st.append(y_val)\n",
    "        x_st.append(x_val)\n",
    "    y_st = np.array(y_st)\n",
    "    x_st = np.array(x_st)\n",
    "    squared_error = np.sum((y_st - neg_growth(x_st, *popt))**2)\n",
    "\n",
    "    new_row = pd.DataFrame({\"exp_nr\":kinetic_curve[\"exp_nr\"].iloc[1], \"max_con\":max(ydata),\n",
    "                        \"theo_max_con\":\"yet to calc\", \"theo_react_end\":\"yet to calc\",\n",
    "                            \"monomer\":kinetic_curve[\"monomer\"].iloc[1], \"RAFT-Agent\":kinetic_curve[\"RAFT-Agent\"].iloc[1],\n",
    "                            \"solvent\":kinetic_curve[\"solvent\"].iloc[1],\n",
    "                            \"fit_p1\":[popt[0]],\"fit_p2\":[popt[1]],\n",
    "                            \"p1_variance\":[pcov[0][0]],\"p1_p2_covariance\":[pcov[0][1]],\"p2_variance\":[pcov[1][1]],\n",
    "                            \"squared_error\":squared_error, \"xdata\":[xdata], \"ydata\":[ydata]})\n",
    "    kinetics_df = pd.concat([kinetics_df, new_row])\n",
    "\n",
    "''' comment out here if plot is needed.\n",
    "    marker_dict = dict(color=colors[idx%len(colors)]) # set same colors per kinetic\n",
    "    fig.add_scatter(x=xdata, y=ydata, mode=\"lines+markers\", opacity=1, name=kinetic_curve[\"exp_nr\"].iloc[1], marker=marker_dict)\n",
    "    add_fits_to_plot(neg_growth, neg_growth_derivative, popt, marker_dict)\n",
    "\n",
    "fig.update_layout(\n",
    "    yaxis=dict(\n",
    "        range=[-0.1,1]\n",
    "    ),\n",
    "    xaxis_title=\"Time [h]\",\n",
    "    yaxis_title=\"Conversion [%]\"\n",
    ")\n",
    "fig.show()\n",
    "# '''\n",
    "\n",
    "kinetics_df.reset_index(drop=True, inplace=True)\n",
    "kinetics_df.drop(axis=\"index\", index=kinetics_df[kinetics_df[\"max_con\"] <= 0].index, inplace=True)\n",
    "kinetics_df.reset_index(drop=True, inplace=True)\n",
    "kinetics_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# normalize the errors by dividing them by their respective standard deviation\n",
    "def normalize_errors(err):\n",
    "    return err / np.std(err)\n",
    "\n",
    "for error in [\"squared_error\", \"p1_variance\", \"p2_variance\", \"p1_p2_covariance\"]:\n",
    "    kinetics_df[error] = normalize_errors(kinetics_df[error])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# kinetics_df[kinetics_df[\"squared_error\"]>0.01] 29/317 entries\n",
    "# calculating covariance between errors to use only the reasonable ones\n",
    "\n",
    "# permutate all combinations of the errors\n",
    "errorcombs = [[],[],[]]\n",
    "for err1, err2 in itertools.combinations([\"squared_error\", \"p1_variance\", \"p2_variance\", \"p1_p2_covariance\"], 2):\n",
    "    # print(f\"The covariance between {err1} and {err2} is {np.cov(kinetics_df[err1], kinetics_df[err2])}\")\n",
    "    # print(f\"The correlation between {err1} and {err2} is {np.correlate(kinetics_df[err1], kinetics_df[err2])}\")\n",
    "    # print(\"\\n\")\n",
    "    errorcombs[0].append(f\"{err1}/{err2}\")\n",
    "    errorcombs[1].append(np.cov(kinetics_df[err1], kinetics_df[err2]))\n",
    "    errorcombs[2].append(*np.correlate(kinetics_df[err1], kinetics_df[err2]))\n",
    "errorcombs_dc = {\"name\": errorcombs[0], \"covariance\":errorcombs[1], \"correlation\":errorcombs[2]}\n",
    "errorcombs_df = pd.DataFrame(data=errorcombs_dc)\n",
    "errorcombs_df[\"i_correlation\"] = errorcombs_df[\"correlation\"] * (-1)\n",
    "\n",
    "# plot bar plot per a pair of errors with superimposed correlation\n",
    "err_fig = px.bar(title=\"Correlation between Errors\", labels={\"correlation\":\"correlation\"}, log_y=True)\n",
    "err_fig.add_bar(x=errorcombs_df[\"name\"], y=errorcombs_df[\"correlation\"], name=\"positive correlation\", marker_color=\"green\")\n",
    "err_fig.add_bar(x=errorcombs_df[\"name\"], y=errorcombs_df[\"i_correlation\"], name=\"negative correlation\", marker_color=\"crimson\")\n",
    "err_fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# violin plots of the errors\n",
    "for errors in [\"p1_variance\", \"p2_variance\", \"p1_p2_covariance\"]:\n",
    "    kinetics_df[errors] = kinetics_df[errors].apply(lambda x: np.absolute(x))\n",
    "fig = px.violin(kinetics_df, y=[\"squared_error\", \"p1_variance\", \"p2_variance\", \"p1_p2_covariance\"], box=True, points=\"all\", log_y=True)\n",
    "fig.update_layout(title=\"Errors normalize by \\u03C3\", xaxis_title=\"Error type\", yaxis_title=\"value\", yaxis=dict(title=\"log(value)\", range=(-22, 3)))\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get information about within which error margin the fits and therefore kinetics are good\n",
    "# split error in quartiles, index per error\n",
    "\n",
    "title_dic = {\"squared_error\":\"r¬≤ - error\",\n",
    "             \"p1_variance\":\"variance of parameter 1\",\n",
    "             \"p2_variance\":\"variance of parameter 2\",\n",
    "             \"p1_p2_covariance\":\"covariance (Params 1 & 2)\"}\n",
    "\n",
    "def get_quartile_indexes(error_type):\n",
    "    quartile_len = len(kinetics_df) / 4\n",
    "    quartile_ranges = np.array([(a * quartile_len, (a + 1) * quartile_len) for a in range(4)], dtype=int)\n",
    "    quartiles_list = list()\n",
    "    for q in range(4):\n",
    "        quartiles_list.append(kinetics_df.sort_values(by=[error_type]).iloc[quartile_ranges[q][0]:quartile_ranges[q][1]])\n",
    "    return quartiles_list\n",
    "\n",
    "def export_quartile_figures():\n",
    "    for err in tqdm([\"squared_error\", \"p1_variance\", \"p2_variance\", \"p1_p2_covariance\"]):\n",
    "        err_quartiles = get_quartile_indexes(err)\n",
    "\n",
    "        # plot the single quartiles\n",
    "        for nr, n in enumerate(err_quartiles):\n",
    "            iks = n.index\n",
    "            fg = px.line(title=f\"kinetics (quartile {nr+1} of the {title_dic[err]}) \", labels={\"x\":\"time\", \"y\":\"conversion\"})\n",
    "            for ik in iks:\n",
    "                marker_dict = dict(color=colors[ik%len(colors)])\n",
    "                fit_data = kinetics_df.iloc[ik]\n",
    "                xdt, ydt = fit_data[\"xdata\"], fit_data[\"ydata\"]\n",
    "                fg.add_scatter(x=xdt, y=ydt, mode=\"lines+markers\", name=kinetic_curves[ik][\"exp_nr\"].iloc[0], marker=marker_dict)\n",
    "                add_fits_to_plot(neg_growth, neg_growth_derivative, [fit_data[\"fit_p1\"], fit_data[\"fit_p2\"]], marker_dict)\n",
    "                fg.update_layout(yaxis=dict(range=[-0.1,1]), xaxis_title=\"time [h]\", yaxis_title=\"conversion [%]\")\n",
    "            fg.write_image(f\"data exploration figures/{err} ({nr+1} quartile).svg\")\n",
    "    print(\"exported\")\n",
    "# export_quartile_figures()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# descry when a function aligns to the datapoints in a reasonable way\n",
    "#   Hence, wheneth' the blunder exaggerates, an 80% betweeneth' of the maximum conversion in that kinetic should be assessed to be the maximum conversion.\n",
    "#   let's give a point for every quartile further from the first for the single errors divided by the maximum score (that is 3*4=12)\n",
    "error_list = [\"squared_error\", \"p1_variance\", \"p2_variance\", \"p1_p2_covariance\"]\n",
    "error_dic = {}\n",
    "score = np.zeros(len(kinetics_df), int)\n",
    "for error in error_list:\n",
    "    quartiles = get_quartile_indexes(error)\n",
    "    # for every error we want to give an error per index\n",
    "    for sc, quartile in enumerate(quartiles):\n",
    "        if sc == 0:\n",
    "            continue\n",
    "        # each quartile is a dataframe, where the latter one raise a higher error ( 0, 1, 2, 3)\n",
    "        for num in quartile.index:\n",
    "            score[num]+=sc\n",
    "kinetics_df[\"error_score\"]=score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "p1_values = kinetics_df[\"fit_p1\"].values\n",
    "average_conversion = p1_values.mean()\n",
    "min_con, max_con = p1_values.min(), p1_values.max()\n",
    "\n",
    "print(f\"According to the fits the mean maximum conversion is {average_conversion:.3n}, the minimum maximum is {min_con:.3n} and the maximum overall is {max_con:.3n}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# determining apposite reaction end values.\n",
    "# The moment where 90% of the maximum conversion have been reached can be seen as a practical maximum conversion point\n",
    "kinetics_df[\"theo_max_con\"] = kinetics_df[\"fit_p1\"].apply(lambda x: x*0.9)\n",
    "\n",
    "def y_converted_negative_growth(y, l, k):\n",
    "    return -np.log(1 - y / l) / k\n",
    "\n",
    "kinetics_df[\"theo_react_end\"] = \\\n",
    "    [y_converted_negative_growth(y, fit_p1, fit_p2) for y, fit_p1, fit_p2 in zip(kinetics_df[\"theo_max_con\"], kinetics_df[\"fit_p1\"], kinetics_df[\"fit_p2\"])]\n",
    "\n",
    "# the theoretical maximal conversion must be capped at reasonable time (we take two days here) that is applying 139/313 entries\n",
    "kinetics_df[\"theo_react_end\"] = [48 if x > 48 else x for x in kinetics_df[\"theo_react_end\"].values]\n",
    "# recalculate the apposite maximal conversion\n",
    "kinetics_df[\"theo_max_con\"] = [neg_growth(x, p1, p2) for x, p1, p2 in zip(kinetics_df[\"theo_react_end\"], kinetics_df[\"fit_p1\"], kinetics_df[\"fit_p2\"])]\n",
    "kinetics_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# doing the same fitting for Mn and investigating the discrepancy.\n",
    "sRt.df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}